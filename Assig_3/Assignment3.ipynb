{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb11eac2",
   "metadata": {},
   "source": [
    "# Aprendizagem Automática Avançada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dcf34b",
   "metadata": {},
   "source": [
    "**Alunos:**\n",
    "    João Raimundo (57454), Rui Roque (57588)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda73c9",
   "metadata": {},
   "source": [
    "\n",
    "## Assigment #3 - Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74708e41",
   "metadata": {},
   "source": [
    "### 0.1 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação das bibliotecas\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647f1b59",
   "metadata": {},
   "source": [
    "### 0.2 - Importação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importação do conjunto de dados breast_cancer\n",
    "x, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "x # features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao visualizar os dados de cima, procedeu-se à standardization das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.29607613,\n",
       "         2.75062224,  1.93701461],\n",
       "       [ 1.82982061, -0.35363241,  1.68595471, ...,  1.0870843 ,\n",
       "        -0.24388967,  0.28118999],\n",
       "       [ 1.57988811,  0.45618695,  1.56650313, ...,  1.95500035,\n",
       "         1.152255  ,  0.20139121],\n",
       "       ...,\n",
       "       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.41406869,\n",
       "        -1.10454895, -0.31840916],\n",
       "       [ 1.83834103,  2.33645719,  1.98252415, ...,  2.28998549,\n",
       "         1.91908301,  2.21963528],\n",
       "       [-1.80840125,  1.22179204, -1.81438851, ..., -1.74506282,\n",
       "        -0.04813821, -0.75120669]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features standardization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "X_scaled = scaler.transform(x)\n",
    "\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4. Definição de Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição de uma função (modelSelection) que faz KFold cross-validation, treinando os modelos e calculando as respetivas previsões e accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelSelection(X_train, y_train, model, acc, predicts, i=1):\n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    TRUTH=None\n",
    "    PREDS=None\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        model.fit(X_train_fold,y_train_fold)\n",
    "        preds = model.predict(X_test_fold)\n",
    "\n",
    "        if TRUTH is None:\n",
    "            PREDS=preds\n",
    "            TRUTH=y_test_fold\n",
    "        else:\n",
    "            PREDS=np.hstack((PREDS, preds))\n",
    "            TRUTH=np.hstack((TRUTH, y_test_fold))\n",
    "    \n",
    "\n",
    "    acc = np.append(acc, accuracy_score(TRUTH, PREDS))\n",
    "    if(i == 0):\n",
    "        predicts = np.append(predicts, PREDS)\n",
    "    else:\n",
    "        predicts = np.vstack((predicts, PREDS))\n",
    "        \n",
    "    return acc, predicts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5. Treino e Teste dos Modelos de Classificação (predictions e respetivos scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleção dos Melhores Modelos de Classificação:\n",
    "\n",
    " * LogisticRegression() \n",
    " * DecisionTreeClassifier() - vários hyperparametros testados\n",
    " * svm.SVC()                - vários hyperparametros testados\n",
    " * RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9771529]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "preds = []\n",
    "\n",
    "# seleção do melhor modelo de logistic regression\n",
    "acc, preds = modelSelection(X_scaled, y, LogisticRegression(max_iter=10000), acc, preds, 0)\n",
    "\n",
    "print(acc)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9771529  0.91212654]\n",
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# seleção do melhor modelo de Decision Tree Classifier com os hiperparâmetros default\n",
    "acc, preds = modelSelection(X_scaled, y, DecisionTreeClassifier(), acc, preds)\n",
    "\n",
    "print(acc)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9771529  0.91212654 0.93673111]\n"
     ]
    }
   ],
   "source": [
    "# seleção do melhor modelo de Decision Tree Classifier com o critério entropia\n",
    "acc, preds = modelSelection(X_scaled, y, DecisionTreeClassifier(criterion=\"entropy\"), acc, preds)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9771529  0.91212654 0.93673111 0.94551845]\n"
     ]
    }
   ],
   "source": [
    "# seleção do melhor modelo de Decision Tree Classifier com o critério entropia e max_depth = 4\n",
    "acc, preds = modelSelection(X_scaled, y, DecisionTreeClassifier(criterion=\"entropy\", max_depth=4), acc, preds)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9771529  0.91212654 0.93673111 0.94551845 0.97012302]\n"
     ]
    }
   ],
   "source": [
    "# seleção do melhor modelo de svm.SVC com os hiperparâmetros default \n",
    "acc, preds = modelSelection(X_scaled, y, svm.SVC(), acc, preds)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9771529  0.91212654 0.93673111 0.94551845 0.97012302 0.89279438]\n"
     ]
    }
   ],
   "source": [
    "# seleção do melhor modelo de svm.SVC com kernel = poly\n",
    "acc, preds = modelSelection(X_scaled, y, svm.SVC(kernel=\"poly\"), acc, preds)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9771529  0.91212654 0.93673111 0.94551845 0.97012302 0.89279438\n",
      " 0.97012302]\n"
     ]
    }
   ],
   "source": [
    "# seleção do melhor modelo de svm.SVC com kernel = rbf\n",
    "acc, preds = modelSelection(X_scaled, y, svm.SVC(kernel=\"rbf\"), acc, preds)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9771529  0.91212654 0.93673111 0.94551845 0.97012302 0.89279438\n",
      " 0.97012302 0.94551845]\n"
     ]
    }
   ],
   "source": [
    "# seleção do melhor modelo de RandomForest com n_estimators = 10\n",
    "acc, preds = modelSelection(X_scaled, y, RandomForestClassifier(n_estimators=10), acc, preds)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(acc))\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.6. Weighted Average Ensemble System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo em conta os scores de accuracy obtidos nos melhores modelos selecionados, aplicou-se a função softmax ao array de accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12919497, 0.12106121, 0.12407681, 0.12517192, 0.12828993,\n",
       "       0.11874331, 0.12828993, 0.12517192])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = softmax(acc)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicação do Weighted Average Ensemble System a partir da fórmula:\n",
    "\n",
    " - round(softmax([a1, a2, . . . , an]) · [f1(X), f2(X), . . . , fn(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wae = np.around(np.dot(acc, preds), decimals=0)\n",
    "wae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base no output do Weighted Average Ensemble System procedeu-se à avaliação do Mixture Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       212\n",
      "           1       0.97      0.99      0.98       357\n",
      "\n",
      "    accuracy                           0.97       569\n",
      "   macro avg       0.98      0.97      0.97       569\n",
      "weighted avg       0.97      0.97      0.97       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, wae))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
